{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requests the access token to the Spotify API, collects and saves raw data in the `.csv` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "from requests import post,get\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token endpoint URI and the format of the request are based on the [information page](https://developer.spotify.com/documentation/web-api/tutorials/getting-started#create-an-app) of Spotify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../.env\", \"r\") as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "\n",
    "url = \"https://accounts.spotify.com/api/token\"\n",
    "\n",
    "headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "\n",
    "data = {\n",
    "    \"grant_type\": \"client_credentials\",\n",
    "    \"client_id\": credentials[\"CLIENT_ID\"],  \n",
    "    \"client_secret\": credentials[\"CLIENT_SECRET\"]\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "response = post(url, headers=headers, data=data)\n",
    "if response.status_code == 200:\n",
    "    access_token = response.json()['access_token']\n",
    "else:\n",
    "    print('Token could not be obtained, status code: ', response.status_code)\n",
    "\n",
    "    \n",
    "def fetch_data(request, header):\n",
    "    response = get(url=request, headers=header)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print('Failure.', response.status_code, response.json())\n",
    "        return {}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having obtained the access token, we can start data collection. First, we will collect IDs of all Spotify playlists from a chosen categoty for the Netherlands region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\"Authorization\": \"Bearer \" + access_token}\n",
    "\n",
    "# Pop playlists were selected as they are most popular\n",
    "category = \"pop\"\n",
    "\n",
    "def get_playlists_links(num_of_playlists = 100):\n",
    "\n",
    "    playlist_ids = []\n",
    "    # maximum number of items to return is set to 50 by Spotify\n",
    "    one_request_max = 50\n",
    "\n",
    "    def extract_links(request, header):\n",
    "        _data_page = fetch_data(request, header)\n",
    "        _df = pd.DataFrame(_data_page[\"playlists\"][\"items\"])\n",
    "        \n",
    "        # return the urls if they are present\n",
    "        if \"href\" in _df.columns:\n",
    "            return _df[\"href\"].tolist()\n",
    "        else:\n",
    "            return []\n",
    "            \n",
    "\n",
    "    # Send repeated requests\n",
    "    offset = 0\n",
    "    for num in range(num_of_playlists // one_request_max):\n",
    "        url = f\"https://api.spotify.com/v1/browse/categories/{category}/playlists?offset={offset}&limit=50\"\n",
    "        playlist_ids.extend(extract_links(url, header))\n",
    "        offset += 50\n",
    "\n",
    "    # collect remaining playlists with smaller limit\n",
    "    if num_of_playlists % one_request_max != 0:\n",
    "        url = f\"https://api.spotify.com/v1/browse/categories/{category}/playlists?offset={offset}&limit={num_of_playlists % one_request_max}\"\n",
    "        playlist_ids.extend(extract_links(url, header))\n",
    "        \n",
    "    if num_of_playlists != len(set(playlist_ids)):\n",
    "        print(f\"In the category {category}, there are fewer playlists than {num_of_playlists}, namely: {len(set(playlist_ids))}.\")\n",
    "    return list(set(playlist_ids))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the category pop, there are fewer playlists than 100, namely: 23.\n"
     ]
    }
   ],
   "source": [
    "playlist_urls = get_playlists_links()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having obtained all playlists from the prespecified category, we can now proceed to collect all the songs that are in those playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_songs_from_playlist(url):\n",
    "\n",
    "    _data = fetch_data(url, header)\n",
    "    \n",
    "    row = {}\n",
    "    row[\"playlist_href\"] = url\n",
    "    row[\"followers\"] = _data[\"followers\"][\"total\"]\n",
    "    row['name'] = _data['name']\n",
    "    row['description'] = _data['description']\n",
    "    # To investigate who is the owner of the playslist -> possible EDA\n",
    "    if _data['owner']['display_name'] != 'Spotify':\n",
    "        print(\"Different owner: \" + _data['owner']['display'])\n",
    "    ## In the end it looked like only Spotify playlists were available with my credentials but\n",
    "    ## I decided to keep the two lines of code above anyway\n",
    "\n",
    "\n",
    "    # A list of song dictionaries to be dealt with in the cleaning process\n",
    "    row['songs'] = _data['tracks']['items']\n",
    "    # Collects remaining songs if the playlist had more than 100 songs\n",
    "    _data = _data['tracks']\n",
    "    \n",
    "    while _data['next'] is not None:\n",
    "        _data = fetch_data(_data['next'], header)\n",
    "        row['songs'].extend(_data['items'])\n",
    "\n",
    "    return row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we apply this function for every playlist\n",
    "playlist_urls_series = pd.Series(playlist_urls)\n",
    "\n",
    "ser = playlist_urls_series.apply(get_songs_from_playlist)\n",
    "\n",
    "# And transform it to a data frame\n",
    "series_data = pd.Series(ser)\n",
    "list_of_dicts = series_data.tolist()\n",
    "df = pd.DataFrame(list_of_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having collected all the data we were interested in, it is time to save it to a file for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/raw/spotify_playlists.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me204env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
