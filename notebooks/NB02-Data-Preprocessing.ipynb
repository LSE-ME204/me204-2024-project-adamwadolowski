{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This notebook is responsible for transformation of raw data collected from Spotify's API and adjusting the structure and data types for storage in a relational database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/raw/spotify_playlists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction\n",
    "I begin with extracting only the information I am interested in and creating separate data frames that later will be transformed into database tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['playlist_id'] = df['playlist_href'].apply(lambda x: x.split('/')[-1])\n",
    "df['songs'] = df['songs'].apply(lambda x: ast.literal_eval(x))\n",
    "# chatGPT helped in the line below\n",
    "df['songs'] = [songs + [{'playlist_id': playlist_id}] for songs, playlist_id in zip(df['songs'], df['playlist_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy was made to avoid SettingWithCopyWarning\n",
    "playlists = df[['playlist_id', 'name', 'description', 'image_url']].copy()\n",
    "playlists['num_followers'] = df['followers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions below are used to create a readily formatted data frame with songs details. `artist_list_to_string` creates a String of artists' names separated by commas (I will use SQLite that cannot store lists), `clean_song_data` extracts only the relevant information for every song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist_list_to_string(artists):\n",
    "    str = \"\"\n",
    "\n",
    "    for artist in artists:\n",
    "        str += artist['name'] + \", \"\n",
    "\n",
    "    str = str[:-2]\n",
    "    return str\n",
    "    \n",
    "def clean_song_data(song: list, playlist_id):\n",
    "    row = {}\n",
    "    song = song['track']\n",
    "\n",
    "    # Some tracks are unavailable in the country associated with the account\n",
    "    if song == None:\n",
    "        return row\n",
    "    \n",
    "    row['song_id'] = song['external_ids']['isrc']\n",
    "    row['playlist_id'] = playlist_id\n",
    "    row['album_id'] = song['album']['id']\n",
    "    row['title'] = song['name']\n",
    "    row['release_date'] = pd.to_datetime(song['album']['release_date'], format='ISO8601')\n",
    "    row['is_explicit'] = song['explicit']\n",
    "    row['album_name'] = song['album']['name']\n",
    "    row['artists'] = artist_list_to_string(song['artists'])\n",
    "    row['popularity'] = song['popularity']\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating new functions we are ready to apply them to transform the songs data into a more managable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatGPT helped in the line below\n",
    "songs = df['songs'].apply(lambda song_list: [clean_song_data(song, song_list[-1]['playlist_id']) for song in song_list[:-1]])\n",
    "songs = songs.explode().apply(pd.Series)\n",
    "\n",
    "# To protect the data frame from the unavailable tracks, I remove rows that have all values equal to NaN\n",
    "songs = songs.dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring the data\n",
    "To remove redundant records and minimize the storage required, data frames are further transormed. That includes removal of duplicates and splitting into smaller tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for duplicates\n",
    "First, we investigate the presence of duplicates. Uniqueness of every playlist is ensured by the return statement of the `get_playlists_links` function in the notebook NB01. Naturally, it should be expected that the same song could be present in multiple playlists. To accomodate future exploratory data analysis, we make a new variable representing the number of appearances a song has in all playlists considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>album_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>is_explicit</th>\n",
       "      <th>album_name</th>\n",
       "      <th>artists</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_occurrences</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QZWBK2200043</td>\n",
       "      <td>37i9dQZF1DX8womvTyUjrN</td>\n",
       "      <td>2GHyrL2mwHWmw1vmQfCrNv</td>\n",
       "      <td>Ké MaL</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>False</td>\n",
       "      <td>Ké MaL</td>\n",
       "      <td>Elsa y Elmar</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USUM72406076</td>\n",
       "      <td>37i9dQZF1DX8womvTyUjrN</td>\n",
       "      <td>27ZCBzP3A8nAMjr2E7JjtB</td>\n",
       "      <td>¿Para Qué?</td>\n",
       "      <td>2024-07-17</td>\n",
       "      <td>False</td>\n",
       "      <td>¿Para Qué?</td>\n",
       "      <td>Ela Taubert</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>USUG12400968</td>\n",
       "      <td>37i9dQZF1DX8womvTyUjrN</td>\n",
       "      <td>5ylbxH7EqpsmHZCRuiYewS</td>\n",
       "      <td>Si Antes Te Hubiera Conocido</td>\n",
       "      <td>2024-06-21</td>\n",
       "      <td>False</td>\n",
       "      <td>Si Antes Te Hubiera Conocido</td>\n",
       "      <td>KAROL G</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      song_id             playlist_id                album_id  \\\n",
       "num_occurrences                                                                 \n",
       "2                QZWBK2200043  37i9dQZF1DX8womvTyUjrN  2GHyrL2mwHWmw1vmQfCrNv   \n",
       "3                USUM72406076  37i9dQZF1DX8womvTyUjrN  27ZCBzP3A8nAMjr2E7JjtB   \n",
       "6                USUG12400968  37i9dQZF1DX8womvTyUjrN  5ylbxH7EqpsmHZCRuiYewS   \n",
       "\n",
       "                                        title release_date is_explicit  \\\n",
       "num_occurrences                                                          \n",
       "2                                      Ké MaL   2024-07-26       False   \n",
       "3                                  ¿Para Qué?   2024-07-17       False   \n",
       "6                Si Antes Te Hubiera Conocido   2024-06-21       False   \n",
       "\n",
       "                                   album_name       artists  popularity  \n",
       "num_occurrences                                                          \n",
       "2                                      Ké MaL  Elsa y Elmar         2.0  \n",
       "3                                  ¿Para Qué?   Ela Taubert        60.0  \n",
       "6                Si Antes Te Hubiera Conocido       KAROL G        94.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The output of this cell motivates the creation of value counts variable\n",
    "songs['num_occurrences'] = songs['song_id'].map(songs['song_id'].value_counts())\n",
    "songs.loc[songs['num_occurrences'] > 1].set_index('num_occurrences').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, multiple songs can come from the same album. To reduce the amount of storage space required, I split the `songs` table into two parts: variables related strictly to songs and related to the albums.\n",
    "\n",
    "I expect to have duplicates in the `albums` and `songs` data frames. To resolve the future issue of dupicates, only one of the duplicates is kept before we proceed further. Also, due to [licensing reasons](https://developer.spotify.com/documentation/web-api/concepts/track-relinking) it is possible that one album may have two or more different IDs. To accomodate for that fact I also keep only one of the album observations that differ only by the ID number.\n",
    "\n",
    "As the next step, I create a table that represents the relation between the songs and the albums they are part of. Similar relation holds for songs and playlists, which is reflected in the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The playlist table was created at the top of the notebook\n",
    "albums = songs[['album_id', 'album_name', 'release_date']].copy()\n",
    "\n",
    "# Mappings between songs, albums and playlists\n",
    "song_album_mapping = songs[['song_id', 'album_id']].copy()\n",
    "song_album_mapping = song_album_mapping.drop_duplicates()\n",
    "\n",
    "song_playlist_mapping = songs[['song_id', 'playlist_id']].copy()\n",
    "song_playlist_mapping = song_playlist_mapping.drop_duplicates()\n",
    "\n",
    "# Removal of duplicates\n",
    "albums = albums.drop_duplicates(subset='album_id')\n",
    "albums = albums.drop_duplicates(subset=['album_name', 'release_date'])\n",
    "\n",
    "songs = songs.drop_duplicates(subset='song_id')\n",
    "# After additional inspection, I found 5 songs that are double counted\n",
    "# As the same song was member of two identical albums (licensing reasons)\n",
    "songs = songs.loc[~songs['song_id'].isin({'USUM72317268', 'GBAHT1901121', 'USAT21001985', 'NLF712406166', 'GMM881200003'})]\n",
    "\n",
    "\n",
    "# Removal of redundant columns\n",
    "songs = songs.drop(columns=['album_id', 'album_name', 'release_date', 'playlist_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining all data frames of interest, I check whether they have any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "album_id        0\n",
      "album_name      0\n",
      "release_date    0\n",
      "dtype: int64\n",
      "song_id            0\n",
      "title              0\n",
      "is_explicit        0\n",
      "artists            0\n",
      "popularity         0\n",
      "num_occurrences    0\n",
      "dtype: int64\n",
      "playlist_id      0\n",
      "name             0\n",
      "description      0\n",
      "image_url        0\n",
      "num_followers    0\n",
      "dtype: int64\n",
      "song_id     0\n",
      "album_id    0\n",
      "dtype: int64\n",
      "song_id        0\n",
      "playlist_id    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(albums.isna().sum())\n",
    "print(songs.isna().sum())\n",
    "print(playlists.isna().sum())\n",
    "print(song_album_mapping.isna().sum())\n",
    "print(song_playlist_mapping.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, my data frames are well-structured, without duplicates and missing values. It is time to prepare a database for their storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of a Relational Database\n",
    "Having cleaned and divided the data into meaningful tables, I move on to creating a database to store all the information. As mentioned previously, I will be using [SQLite](https://www.sqlite.org/index.html) because the database can be stored locally and the limitation of maximum one open connection is not an issue for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%config SqlMagic.autocommit=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modification of Data Types\n",
    "To ensure efficient and reliable storage of information in the database, I change the column types to minimize the memory space assigned to store the values. My type choices are based on a manual inspection of the values every column takes and the otuput of the cell below. For example, `album_id` is always a 22-character string, whereas the lengths of `album_names` vary but the longest name has 84 characters. In case you are curious, it is the 'Spider-Man: Into the Spider-Verse (Soundtrack From & Inspired by the Motion Picture)' album."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of a string in the album_name column is 118.\n",
      "Max length of a string in the title column is 143.\n",
      "Max length of a string in the artists column is 311.\n"
     ]
    }
   ],
   "source": [
    "def check_max_length(df, col):\n",
    "    max = df[col].apply(lambda x: len(list(x))).max()\n",
    "    print(f'Max length of a string in the {col} column is {max}.')\n",
    "    \n",
    "check_max_length(albums, 'album_name')\n",
    "check_max_length(songs, 'title')\n",
    "check_max_length(songs, 'artists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, all tables' schemas are created with appropriate choice of data types and primary keys. Additionally, uniqueness constraints were added were possible to enable faster data retrival and foreign key constraints were added to ensure integrity of references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Connecting to &#x27;db&#x27;</span>"
      ],
      "text/plain": [
       "Connecting to 'db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql sqlite:///../data/clean/spotify_playlists.db --alias db\n",
    "\n",
    "CREATE TABLE albums\n",
    "(\n",
    "    album_id CHAR(22) PRIMARY KEY,\n",
    "    album_name VARCHAR(84),\n",
    "    release_date DATE,\n",
    "    UNIQUE (album_name, release_date)\n",
    ");\n",
    "\n",
    "CREATE TABLE songs\n",
    "(\n",
    "    song_id CHAR(12) PRIMARY KEY,\n",
    "    title VARCHAR(106),\n",
    "    is_explicit BOOLEAN,\n",
    "    artists VARCHAR(70),\n",
    "    popularity TINYINT,\n",
    "    num_occurrences TINYINT\n",
    ");\n",
    "\n",
    "CREATE TABLE song_album_map\n",
    "(\n",
    "    song_id CHAR(12),\n",
    "    album_id CHAR(22),\n",
    "    PRIMARY KEY (song_id, album_id),\n",
    "    FOREIGN KEY (song_id) REFERENCES songs(song_id),\n",
    "    FOREIGN KEY (album_id) REFERENCES albums(album_id)\n",
    "    \n",
    ");\n",
    "\n",
    "CREATE TABLE song_playlist_map\n",
    "(\n",
    "    song_id CHAR(12),\n",
    "    playlist_id CHAR(22),\n",
    "    PRIMARY KEY (song_id, playlist_id),\n",
    "    FOREIGN KEY (song_id) REFERENCES songs(song_id),\n",
    "    FOREIGN KEY (playlist_id) REFERENCES playlists(playlist_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE playlists\n",
    "(\n",
    "    playlist_id CHAR(22) PRIMARY KEY,\n",
    "    name VARCHAR(50),\n",
    "    description VARCHAR(100),\n",
    "    num_followers INT,\n",
    "    image_url CHAR(64),\n",
    "    UNIQUE (name, description, image_url)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I can populate the tables with the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3890"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('../data/clean/spotify_playlists.db')\n",
    "\n",
    "albums.to_sql('albums', conn, if_exists='append', index=False)\n",
    "songs.to_sql('songs', conn, if_exists='append', index=False)\n",
    "playlists.to_sql('playlists', conn, if_exists='append', index=False)\n",
    "song_album_mapping.to_sql('song_album_map', conn, if_exists='append', index=False)\n",
    "song_playlist_mapping.to_sql('song_playlist_map', conn, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me204env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
